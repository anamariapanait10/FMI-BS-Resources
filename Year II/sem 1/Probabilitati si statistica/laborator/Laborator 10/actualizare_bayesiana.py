# -*- coding: utf-8 -*-
"""Actualizare Bayesiana.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eUvUwmhkOeL7jcOALU6gRc79XC2eABTk
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import logistic
from scipy.stats import norm
from math import e
import math

def generate_hypothesis(N, prior): 

  bernoulli_values = []
  for i in range(N): 
    x = np.random.uniform(0, 1)
    if x < prior:
      bernoulli_values.append(1)
    else:
      bernoulli_values.append(0)

  return bernoulli_values

def generate_sample_after_distribution(theta):

    x = np.random.uniform(0, 1)
    if x < theta:
      return 1
 
    return 0

def generate_data(N, labels, verosimility):

  data = []

  for i in range(N):
    if labels[i] == 1:
      data.append(generate_sample_after_distribution(verosimility[0]))
    else:
      data.append(generate_sample_after_distribution(verosimility[1]))


  return data

def main():

  N = 1000
  labels = generate_hypothesis(N, 0.3)
  verosimility = [0.2, 0.6]
  data = generate_data(N, labels, verosimility)

  print(labels)
  print(data)


  cat_1 = [x for x in labels if x == 1]
  print(len(cat_1)/N) #P(label = 1) a priori


  ver_1 = 0
  for i in range(N):
    if labels[i] == 1:
      ver_1 += data[i]

  print(ver_1/len(cat_1))

  #P(x = 1 | label = 1) verosimilitatea ptr cat 1


  cat_0 = [x for x in labels if x == 0]
  print(len(cat_0)/N) #P(label = 0) a priori


  ver_0 = 0
  for i in range(N):
    if labels[i] == 0:
      ver_0 += data[i]

  print(ver_0/len(cat_0))
  #P(x = 1 | label = 0) verosimilitatea ptr cat 0


  data_1 = [x for x in data if x == 1]
  data_0 = [x for x in data if x == 0]

  print(len(data_1)/N) #P(x = 1)
  print(len(data_0)/N) #P(x = 0)

  
  #P(x = 1) = P(x = 1 | label = 0) * P( label = 0) + P(x = 1 | label = 1) * P( label = 1) = 0.6 * 0.7 + 0.2 * 0.3 = 0.48

  #P(label = 1 | x = 1) = (P(x = 1 | label = 1) * P(label = 1)) / P(x = 1) = 0.06/0.48 = 0.125

  post_1 = 0
  for i in range(N):
    if data[i] == 1:
      post_1 += labels[i]

  print(post_1/len(data_1))

  a_posteriori = [0 for i in range(N)]
  
  if data[0] == 1:
    a_posteriori[0] = labels[0]

  ctr = 0

  P = []
  for i in range(1, N):
    if data[i] == 1:
      a_posteriori[i] = a_posteriori[i - 1] + labels[i]
      ctr += 1
      P.append(a_posteriori[i] / ctr)
    else:
      a_posteriori[i] = a_posteriori[i - 1]
      if ctr != 0:
        P.append(a_posteriori[i] / ctr)
 
      
  plt.plot(P)
  plt.show()





if __name__ == "__main__":
  main()

print(0.6 * 0.7 + 0.2 * 0.3)
print(0.06/0.48)

def hypothesis_continuous(N):
   
  x = np.random.uniform(0, 1, N)
  return x

def gen_sample_param(theta):
    
    unif = np.random.uniform(0, 1)
    log = np.log(unif)
    exp_simulated = log * (-1) * (1/theta)

    return exp_simulated

def gen_data(N, labels):

  data = []
  for i in range(N):
    data.append(gen_sample_param(labels[i]))

  return data

def count_in_int(a, b, samples):

  ctr = 0
  for i in range(len(samples)):
    if a < samples[i] and b > samples[i]:
      ctr += 1

  return ctr/len(samples)

def main():

  N = 1000
  labels = hypothesis_continuous(N)

  data = gen_data(N, labels)


  #P(theta) = 1dt
  #P(x|theta) = theta * e^{-theta * x} dx
  #P(x) = integrala(P(theta) * P(x|theta)) dt = ceva cu dx
  #P(theta|x) = ceva cu dt


  #intervale ptr theta, si ptr fiecare t, avem intervale ptr x (Exponentiala)
  #P(theta) = #ncf/#lungimea unui interval
  
  intervals = np.linspace(0, 1, 10)
  print(intervals)
  
  freq_labels = []
  for i in range(9):
    freq_labels.append(count_in_int(intervals[i], intervals[i + 1], labels))
    
  print(freq_labels)

  for i in range(N):
    # functie care identifica in ce interval se afla labelul curent
    # o sa consideram ca x este distribuit conform geom de parametru mijlocul intervalului
    # ptr fiecare x vedem distributia; impartim in intervale samd; 


if __name__ == "__main__":
  main()